# -*- coding: utf-8 -*-
"""ML Telecostumer churn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12yKv4raq5Cb5ATmK9CLSQQDx_YpGhMwa

#Customer Churn Prediction
Customer attrition or churn, is when customers stop doing business with a company. It can have a significant impact on a company's revenue and it's crucial for businesses to find out the reasons why customers are leaving and take steps to reduce the number of customers leaving. One way to do this is by identifying customer segments that are at risk of leaving, and implementing retention strategies to keep them. Also, by using data and machine learning techniques, companies can predict which customers are likely to leave in the future and take actions to keep them before they decide to leave.

We are going to build a basic model for predicting customer churn using Telco Customer Churn dataset. We are using some classification algorithm to model customers who have left, using Python tools such as pandas for data manipulation and matplotlib for visualizations.

Let's get started.

#Steps Involved to Predict Customer Churn
#1. Importing Libraries
#2. Loading Dataset
#3. Exploratory Data Analysis
#4. Feature Engineering
#5. Cleaning and Transforming Data
#6. One-hot Encoding
#9. Feature Scaling
#10. Feature Selection
#11. Prediction using Logistic Regression
#12. Prediction using Support Vector Classifier
#13. Prediction using Decision Tree Classifier
#14. Prediction using KNN Classifier

1. Importing Libraries
"""

import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt
import seaborn as sns

from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import confusion_matrix , classification_report
from imblearn.over_sampling import SMOTE
from xgboost import XGBClassifier
import warnings
warnings.filterwarnings("ignore")



"""# Data Preprocessing

2. Loading Dataset
"""

data = pd.read_csv('/content/WA_Fn-UseC_-Telco-Customer-Churn.csv')
data

data.shape

"""3. Exploratory Data Analysis"""

data.info()

# The column 'total charges' is object so let's convert it
data["TotalCharges"] = (pd.to_numeric(data["TotalCharges"],errors="coerce"))
# we used (errors=coerce) beacause some values have spaces

data.isnull().sum()

data[np.isnan(data["TotalCharges"])]

data.skew(numeric_only= True)

data.corr(numeric_only= True)

# the Tenure column is 0 for these entries even though the MonthlyCharges column is not empty.
# since there are only 11 rows and deleting them will not affect the data

data.dropna(inplace=True)

"""We have 2 types of features in the dataset: categorical (two or more values and without any order) and numerical. Most of the feature names are self-explanatory, except for:

Partner: whether the customer has a partner or not (Yes, No),

Dependents: whether the customer has dependents or not (Yes, No),

OnlineBackup: whether the customer has online backup or not (Yes, No, No internet service),

tenure: number of months the customer has stayed with the company,

MonthlyCharges: the amount charged to the customer monthly,

TotalCharges: the total amount charged to the customer.
There are 7043 customers in the dataset and 19 features without customerID (non-informative) and Churn column (target variable). Most of the categorical features have 4 or less unique values.
"""

data.shape

data.isnull().sum()

"""unique values of each columns which are obejct"""

for i in data.columns[1:]:
    if data[i].dtype == "object":
        print(i,data[i].value_counts().index.values)

with sns.color_palette("pastel"):
    fig, axes = plt.subplots(2, 3, figsize=(12, 7), sharey=True)
    sns.countplot(data=data, x='gender', ax=axes[0, 0])
    sns.countplot(data=data, x='SeniorCitizen', ax=axes[0, 1])
    sns.countplot(data=data, x='Partner', ax=axes[0, 2])
    sns.countplot(data=data, x='Dependents', ax=axes[1, 0])
    sns.countplot(data=data, x='PhoneService', ax=axes[1, 1])
    sns.countplot(data=data, x='PaperlessBilling', ax=axes[1, 2])

with sns.color_palette("pastel"):
    sns.countplot(x="InternetService", data=data)

with sns.color_palette("pastel"):
    fig, axes = plt.subplots(2, 3, figsize=(12, 7), sharey=True)
    sns.countplot(x="StreamingTV", data=data, ax=axes[0,0])
    sns.countplot(x="StreamingMovies", data=data, ax=axes[0,1])
    sns.countplot(x="OnlineSecurity", data=data, ax=axes[0,2])
    sns.countplot(x="OnlineBackup", data=data, ax=axes[1,0])
    sns.countplot(x="DeviceProtection", data=data, ax=axes[1,1])
    sns.countplot(x="TechSupport", data=data, ax=axes[1,2])

with sns.color_palette("pastel"):
    plt.figure(figsize=(8,4))
    sns.countplot(x="Contract", data=data)

with sns.color_palette("pastel"):
    plt.figure(figsize=(10,5))
    sns.countplot(x="PaymentMethod", data=data)

with sns.color_palette("husl"):
    fig, axes = plt.subplots(1,3, figsize=(12, 7))
    sns.histplot(data["tenure"], ax=axes[0])
    sns.histplot(data["MonthlyCharges"], ax=axes[1])
    sns.histplot(data["TotalCharges"], ax=axes[2])



"""**Feature Engineering**

Raw data can be transformed into features that are suitable for machine learning models that process called feature engineering.In this project, we will label encoding for categorical variables that have two values, one hot encoding for categorical variables that have more than two values, and feature calling for numerical variables.

Label Encoding

Label encoding aims to convert categorical variables to numerical format. In this project, we will change categorical variables that have two values such as (Partner, Dependents, PhoneService, Churn, PaperlessBilling, and gender). Values of them just have Yes or No and we will change to 1 and 0 except gender is Female to 1 and Male to 0.


"""

data.replace('No internet service','No',inplace=True)
data.replace('No phone service','No',inplace=True)

for i in data.columns[1:]:
    if data[i].dtype == "object":
        print(i,data[i].value_counts().index.values)

data.drop("customerID",axis="columns",inplace=True)

data.replace({'Yes': 1,'No': 0,'Female':1,'Male':0},inplace=True)
data

"""One Hot Encoding

Same with label encoding, one hot encoding also changes categorical variables to numerical variables. But, one hot encoding takes more than two values. One hot encoding creates a new binary integer (1 or 0) column for each level of the categorical variable.
"""

data = pd.get_dummies(data=data, columns=['InternetService','Contract','PaymentMethod'])
data

"""**Feature Scaling**

In this project, we use MinMaxScaler for feature scaling. MinMaxScaler can make numerical variables scaled from the range 0 to 1. Feature scaling is important to interpret machine learning models to have features on the same scale. We will be scaling numerical variables such as MonthlyCharges, TotalCharges, and tenure.
"""

scale_col = ['tenure','MonthlyCharges','TotalCharges']
scaler = MinMaxScaler()
data[scale_col] = scaler.fit_transform(data[scale_col])
data

"""# Model

Train_Test split
"""

X = data.drop("Churn",axis="columns")
y = data["Churn"]

X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=42,
                                                    test_size=0.2,stratify=y)

"""# Handeling Imbalance"""

y_train.value_counts()

smote = SMOTE(random_state=0)

X_train, y_train = smote.fit_resample(X_train,y_train)
X_test, y_test = smote.fit_resample(X_test,y_test)

y_train.value_counts()

from sklearn.model_selection import train_test_split, cross_val_score,KFold, StratifiedKFold
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc

"""# Logistic Regression Model"""

# Create a logistic regression model
model = LogisticRegression()

# Train the model
model.fit(X_train, y_train)

# Predict on the testing set
y_pred = model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
report = classification_report(y_test, y_pred)

print("Accuracy:", accuracy)
print("Confusion Matrix:\n", conf_matrix)
print("Classification Report:\n", report)

# Predict probabilities for ROC analysis
y_scores = model.predict_proba(X_test)[:, 1]

# Compute ROC curve and AUC
fpr, tpr, thresholds = roc_curve(y_test, y_scores)
roc_auc = auc(fpr, tpr)

# Plot ROC curve
plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")
plt.show()

"""# SVM Classifier"""

from sklearn.svm import SVC
svm = SVC(kernel='linear', probability=True)
#svm = svm.SVC()
svm.fit(X_train, y_train)
y_pred = svm.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
report = classification_report(y_test, y_pred)

print("Accuracy:", accuracy)
print("Confusion Matrix:\n", conf_matrix)
print("Classification Report:\n", report)

# Predict probabilities for ROC analysis
y_scores = svm.predict_proba(X_test)[:, 1]

# Compute ROC curve and AUC
fpr, tpr, thresholds = roc_curve(y_test, y_scores)
roc_auc = auc(fpr, tpr)

# Plot ROC curve
plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")
plt.show()

"""# Decision Tree Classifier"""

from sklearn.tree import DecisionTreeClassifier
dtree = DecisionTreeClassifier()
dtree.fit(X_train, y_train)
y_pred = dtree.predict(X_test)
# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
report = classification_report(y_test, y_pred)

print("Accuracy:", accuracy)
print("Confusion Matrix:\n", conf_matrix)
print("Classification Report:\n", report)

# Predict probabilities for ROC analysis
y_scores = dtree.predict_proba(X_test)[:, 1]

# Compute ROC curve and AUC
fpr, tpr, thresholds = roc_curve(y_test, y_scores)
roc_auc = auc(fpr, tpr)

# Plot ROC curve
plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")
plt.show()

"""#**XGBoost Classifier**"""

from xgboost import XGBClassifier
xgb_model = XGBClassifier()
xgb_model.fit(X_train, y_train)
y_pred = xgb_model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
report = classification_report(y_test, y_pred)

print("Accuracy:", accuracy)
print("Confusion Matrix:\n", conf_matrix)
print("Classification Report:\n", report)

# Predict probabilities for ROC analysis
y_scores = xgb_model.predict_proba(X_test)[:, 1]

# Compute ROC curve and AUC
fpr, tpr, thresholds = roc_curve(y_test, y_scores)
roc_auc = auc(fpr, tpr)

# Plot ROC curve
plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")
plt.show()

"""# KNN"""

from sklearn.neighbors import KNeighborsClassifier

# Create a KNN classifier
knn = KNeighborsClassifier(n_neighbors=5)

# Train the model
knn.fit(X_train, y_train)
# Make predictions
y_pred = knn.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
report = classification_report(y_test, y_pred)

print("Accuracy:", accuracy)
print("Confusion Matrix:\n", conf_matrix)
print("Classification Report:\n", report)

# Predict probabilities for ROC analysis
y_scores = knn.predict_proba(X_test)[:, 1]

# Compute ROC curve and AUC
fpr, tpr, thresholds = roc_curve(y_test, y_scores)
roc_auc = auc(fpr, tpr)

# Plot ROC curve
plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")
plt.show()

"""

# Random Forest

"""

from sklearn.ensemble import RandomForestClassifier
rfc = RandomForestClassifier()
rfc.fit(X_train, y_train)
y_pred = rfc.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
report = classification_report(y_test, y_pred)

print("Accuracy:", accuracy)
print("Confusion Matrix:\n", conf_matrix)
print("Classification Report:\n", report)

# Predict probabilities for ROC analysis
y_scores = rfc.predict_proba(X_test)[:, 1]

# Compute ROC curve and AUC
fpr, tpr, thresholds = roc_curve(y_test, y_scores)
roc_auc = auc(fpr, tpr)

# Plot ROC curve
plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")
plt.show()

"""**Applying Neural Network**"""

X_train

from sklearn.preprocessing import StandardScaler
scaler=StandardScaler()
X_train_scaled=scaler.fit_transform(X_train)
X_test_sclaed=scaler.transform(X_test)

model=Sequential(

    [Dense(20, input_shape=(26,), activation='relu'),

     Dense(10, activation='relu'),

     Dense(1,activation="sigmoid")])


model.compile(optimizer="adam", loss='binary_crossentropy', metrics=['accuracy'])
model.summary()

X_train=tf.convert_to_tensor(X_train, dtype=tf.float32)
y_train=tf.convert_to_tensor(y_train, dtype=tf.float32)
X_test=tf.convert_to_tensor(X_test, dtype=tf.float32)
y_test=tf.convert_to_tensor(y_test, dtype=tf.float32)

model.fit(X_train, y_train, epochs=100, validation_split=0.2)



from sklearn.model_selection import KFold, cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from xgboost import XGBClassifier
from keras.wrappers.scikit_learn import KerasClassifier
from keras.models import Sequential
from keras.layers import Dense
import numpy as np

# Define the k-fold cross-validation configuration
kfold = KFold(n_splits=5, shuffle=True, random_state=1)

# Function to build the Keras ANN model
def build_ann_model():
    model = Sequential([
        Dense(20, input_shape=(X.shape[1],), activation='relu'),
        Dense(10, activation='relu'),
        Dense(1, activation='sigmoid')
    ])
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    return model

# Create dictionary of models including ANN
models = {
    'Logistic Regression': LogisticRegression(max_iter=1000),
    'SVM': SVC(),
    'Decision Tree': DecisionTreeClassifier(),
    'Random Forest': RandomForestClassifier(),
    'KNN': KNeighborsClassifier(),
    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'),
    'ANN': KerasClassifier(build_fn=build_ann_model, epochs=100, batch_size=32, verbose=0)
}

# Evaluate each model using cross-validation
for name, model in models.items():
    scores = cross_val_score(model, X, y, cv=kfold, scoring='accuracy')
    print(f'{name}: Cross-validation scores: {scores}')
    print(f'{name}: Mean Accuracy: {np.mean(scores):.2f}')

from sklearn.model_selection import cross_val_score

accuracies = cross_val_score(estimator=model, scoring="accuracy", X=X_train, y=y_train, cv=5)

print(accuracies)



y_log=model.predict(X_test)

y_pred=np.where(y_log>0.6,1,0)

from sklearn.metrics import accuracy_score
accuracy_score(y_test,y_pred)



model.evaluate(X_test, y_test)

yp = model.predict(X_test)
y_pred = []
for element in yp:
    if element > 0.5:
        y_pred.append(1)
    else:
        y_pred.append(0)

classification_report(y_test,y_pred)

confusion_matrix(y_test,y_pred)

# Calculate ROC curve
fpr, tpr, thresholds = roc_curve(y_test, yp)

# Calculate AUC
roc_auc = auc(fpr, tpr)

# Plot ROC curve
plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

"""**Performing Cross Validation on training data**"""

# Define the k-fold cross-validation configuration
kfold = KFold(n_splits=5, shuffle=True, random_state=1)

# Create dictionary of models
models = {
    'Logistic Regression': LogisticRegression(max_iter=1000),
    'SVM': SVC(),
    'Decision Tree': DecisionTreeClassifier(),
    'Random Forest': RandomForestClassifier(),
    'KNN': KNeighborsClassifier(),
    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')
}

# Evaluate each model using cross-validation
for name, model in models.items():
    scores = cross_val_score(model, X, y, cv=kfold, scoring='accuracy')
    print(f'{name}:Cross-validation scores: {scores}')
    print(f'{name}: Mean Accuracy: {np.mean(scores):.2f}')

""" k-fold cross-validatione on neural network"""

# Define th K-fold cross-validatione configuration
kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# Perform cross-validation
scores = cross_val_score(model, X, y, cv=kfold, scoring='accuracy')

# Print cross-validation results
print("Accuracies:", scores)
print("Mean Accuracy: {:.2f}%".format(np.mean(scores)))



"""# **Conclusion**
So, Thank you for sticking with me until the end. If you are interested in learning more about this dataset, you can explore other machine learning classification models such as Gradient Boosting Classifier, Stochastic Gradient Boosting (SGB) Classifierand Cat Boost Classifier etc . Additionally, you can try tuning the model's hyperparameters using techniques like GridSearchCV. I am not going into detail about those topics, but if you are interested, feel free to explore them further.


"""